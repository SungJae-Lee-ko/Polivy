"""DC ìë£Œ ìë™í™” ì•± â€” Streamlit ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸."""

import io
import json
import logging
import os
import re
import sys
import time
from pathlib import Path

import streamlit as st
from docx import Document

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from config.settings import HOSPITAL_META_PATH, PRODUCTS_JSON_PATH
from config.placeholder_queries import PLACEHOLDER_QUERIES
from utils.ai_engine import RAGEngine, CellTagMapping
from utils.doc_processor import (
    detect_taggable_cells,
    find_placeholders_in_doc,
    insert_placeholder_tags,
    replace_placeholders_to_bytes,
    TaggableCell,
    CellType,
)
from utils.pdf_loader import build_vectorstore

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="DC ìë£Œ ìë™í™”",
    page_icon="ğŸ’Š",
    layout="wide",
)

st.title("ğŸ’Š DC ìë£Œ ìë™í™”")
st.caption("ë³‘ì› ì•½ì œìœ„ì›íšŒ(DC) ìƒì • ìë£Œë¥¼ AIë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_json(path: Path) -> dict:
    """JSON íŒŒì¼ ë¡œë“œ."""
    with open(path, encoding="utf-8") as f:
        return json.load(f)


def _save_json(path: Path, data: dict) -> None:
    """JSON íŒŒì¼ ì €ì¥."""
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def _init_session_state() -> None:
    """Streamlit session state ì´ˆê¸°í™”.

    RAG ì—”ì§„, ì¸ë±ì‹± ìƒíƒœ, íƒœê·¸ ì—ë””í„° ìƒíƒœ ë“±ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    defaults = {
        "google_api_key": os.getenv("GOOGLE_API_KEY", ""),
        "vectorstore": None,
        "rag_engine": None,
        "selected_product": None,
        "selected_hospital": None,
        "indexed_files": [],
        "indexed_chunks": 0,
        "generated_results": {},       # {ì§ˆë¬¸ í…ìŠ¤íŠ¸: ìƒì„±ëœ ë‹µë³€}
        "generated_sources": {},       # {ì§ˆë¬¸ í…ìŠ¤íŠ¸: ì†ŒìŠ¤ ëª©ë¡}
        "fillable_cells": [],          # FillableCell ëª©ë¡
        "cell_fills": {},              # {(ti,ri,ci): ë‹µë³€} â€” ìµœì¢… ì…€ ì±„ìš°ê¸°ìš©
    }
    for key, val in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = val


_init_session_state()

TEMPLATES_DIR = Path("templates")
TEMPLATES_DIR.mkdir(exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒœê·¸ ì—ë””í„° í—¬í¼ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _build_cells_from_tagged_doc(doc_path: Path) -> tuple[list[TaggableCell], dict]:
    """ì´ë¯¸ íƒœê·¸ëœ .docxì—ì„œ {{key}} ì…€ ì¶”ì¶œ.

    ì¬í¸ì§‘ ëª¨ë“œì—ì„œ ê¸°ì¡´ íƒœê·¸ í‚¤ë¥¼ selectbox ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨.

    Args:
        doc_path: íƒœê·¸ëœ .docx íŒŒì¼ ê²½ë¡œ

    Returns:
        (TaggableCell ëª©ë¡, {(ti, ri, ci): placeholder_key ë§¤í•‘})
    """
    doc = Document(str(doc_path))
    cells = []
    key_map = {}
    placeholder_pattern = re.compile(r"\{\{(\w+)\}\}")

    for ti, table in enumerate(doc.tables):
        for ri, row in enumerate(table.rows):
            seen = set()
            for ci, cell in enumerate(row.cells):
                # ë³‘í•© ì…€ ì¤‘ë³µ ì œê±°
                if id(cell._tc) in seen:
                    continue
                seen.add(id(cell._tc))

                text = cell.text.strip()
                matches = placeholder_pattern.findall(text)

                if matches:
                    key = matches[0]
                    key_map[(ti, ri, ci)] = key

                    # cell_type íŒë³„
                    if text == f"{{{{{key}}}}}":
                        cell_type = CellType.EMPTY
                        question = ""
                    else:
                        cell_type = CellType.LABEL_ONLY
                        question = text.replace(f"{{{{{key}}}}}", "").strip()

                    cells.append(TaggableCell(
                        table_index=ti,
                        row_index=ri,
                        cell_index=ci,
                        question=question or text,
                        current_text=text,
                        cell_type=cell_type,
                    ))

    return cells, key_map


def _strip_all_placeholder_tags(doc_path: Path) -> bytes:
    """ì¬í¸ì§‘ ì €ì¥ ì‹œ ê¸°ì¡´ {{key}} ëª¨ë‘ ì œê±°í•œ bytes ë°˜í™˜.

    insert_placeholder_tags() í˜¸ì¶œ ì „ íŒŒì¼ì— ê¸°ë¡í•˜ì—¬ ì´ì¤‘ íƒœê·¸ ë°©ì§€.

    Args:
        doc_path: .docx íŒŒì¼ ê²½ë¡œ

    Returns:
        íƒœê·¸ ì œê±°ëœ .docx íŒŒì¼ì˜ bytes
    """
    doc = Document(str(doc_path))
    placeholder_pattern = re.compile(r"\{\{\w+\}\}")

    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for para in cell.paragraphs:
                    for run in para.runs:
                        if placeholder_pattern.search(run.text):
                            run.text = placeholder_pattern.sub("", run.text)

    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.read()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # API Key
    api_key_input = st.text_input(
        "Google API Key",
        value=st.session_state.google_api_key,
        type="password",
        placeholder="AIza...",
        help="Google AI Studioì—ì„œ ë°œê¸‰í•œ API í‚¤",
    )
    if api_key_input != st.session_state.google_api_key:
        st.session_state.google_api_key = api_key_input
        st.session_state.rag_engine = None

    st.divider()

    # ì œí’ˆ ì„ íƒ
    st.subheader("1ï¸âƒ£ ì œí’ˆ ì„ íƒ")
    try:
        products_data = _load_json(PRODUCTS_JSON_PATH)
        product_list = products_data.get("products", [])
    except FileNotFoundError:
        st.error(f"products.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {PRODUCTS_JSON_PATH}")
        product_list = []

    if product_list:
        product_names = [p["name"] for p in product_list]
        selected_product_name = st.selectbox("ì œí’ˆ", product_names, key="product_select")
        new_product = next(p for p in product_list if p["name"] == selected_product_name)

        if new_product != st.session_state.selected_product:
            st.session_state.selected_product = new_product
            st.session_state.vectorstore = None
            st.session_state.rag_engine = None
            st.session_state.indexed_files = []
            st.session_state.indexed_chunks = 0
            st.session_state.generated_results = {}
    else:
        st.warning("ë“±ë¡ëœ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # ë³‘ì› ì„ íƒ
    st.subheader("2ï¸âƒ£ ë³‘ì› ì„ íƒ")
    try:
        hospital_data = _load_json(HOSPITAL_META_PATH)
        hospital_list = hospital_data.get("hospitals", [])
    except FileNotFoundError:
        hospital_list = []

    real_hospitals = [h for h in hospital_list if h.get("id") != "sample_hospital"]

    if real_hospitals:
        hospital_names = [h["name"] for h in real_hospitals]
        selected_hospital_name = st.selectbox("ë³‘ì›", hospital_names, key="hospital_select")
        new_hospital = next(h for h in real_hospitals if h["name"] == selected_hospital_name)

        if new_hospital != st.session_state.selected_hospital:
            st.session_state.selected_hospital = new_hospital
            st.session_state.generated_results = {}
            st.session_state.auto_mapping_done = False
            st.session_state.field_mapping = []

        is_ready = new_hospital.get("mode") == "manual"
        st.caption("ìƒíƒœ: **ì¤€ë¹„ë¨** âœ…" if is_ready else "ìƒíƒœ: **íƒœê·¸ ì„¤ì • í•„ìš”** âš ï¸")
    else:
        st.info("ë“±ë¡ëœ ë³‘ì›ì´ ì—†ìŠµë‹ˆë‹¤.\n\n**ë³‘ì› ì–‘ì‹ ê´€ë¦¬** íƒ­ì—ì„œ ì¶”ê°€í•˜ì„¸ìš”.")
        st.session_state.selected_hospital = None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ íƒ­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab_generate, tab_hospitals = st.tabs(["ğŸ“„ ë¬¸ì„œ ìƒì„±", "ğŸ¥ ë³‘ì› ì–‘ì‹ ê´€ë¦¬"])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# íƒ­ 1: ë¬¸ì„œ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab_generate:
    product = st.session_state.selected_product
    hospital = st.session_state.selected_hospital
    api_key = st.session_state.google_api_key

    # â”€â”€ Step 1: Master Data ê´€ë¦¬ â”€â”€
    st.header("Step 1: Master Data (ê¸°ì¤€ ë¬¸ì„œ) ì—…ë¡œë“œ")

    if not product:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.")
    else:
        master_data_dir = Path(product["master_data_dir"])
        master_data_dir.mkdir(parents=True, exist_ok=True)
        existing_pdfs = sorted(master_data_dir.glob("*.pdf"))

        col1, col2 = st.columns([3, 1])
        with col1:
            if existing_pdfs:
                st.success(f"ì €ì¥ëœ PDF: **{len(existing_pdfs)}ê°œ** â€” {', '.join(f.name for f in existing_pdfs)}")
            else:
                st.warning("ì €ì¥ëœ Master Dataê°€ ì—†ìŠµë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        with col2:
            if existing_pdfs and st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”", help="ì €ì¥ëœ PDFë¥¼ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤"):
                for pdf in existing_pdfs:
                    pdf.unlink()
                st.session_state.vectorstore = None
                st.session_state.rag_engine = None
                st.session_state.indexed_files = []
                st.session_state.indexed_chunks = 0
                st.rerun()

        uploaded_files = st.file_uploader(
            "PDF ì¶”ê°€ ì—…ë¡œë“œ",
            type=["pdf"],
            accept_multiple_files=True,
            key="pdf_uploader",
        )
        if uploaded_files:
            for uf in uploaded_files:
                with open(master_data_dir / uf.name, "wb") as f:
                    f.write(uf.getbuffer())
            st.success(f"{len(uploaded_files)}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
            st.session_state.vectorstore = None
            st.session_state.rag_engine = None

        all_pdfs = sorted(master_data_dir.glob("*.pdf"))
        if all_pdfs:
            if st.session_state.vectorstore is None:
                if not api_key:
                    st.warning("Google API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ì¸ë±ì‹±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                elif st.button("ğŸ” ì¸ë±ì‹± ì‹œì‘", type="primary"):
                    with st.spinner(f"{len(all_pdfs)}ê°œ PDF ì¸ë±ì‹± ì¤‘..."):
                        try:
                            vectorstore = build_vectorstore(
                                file_paths=[str(p) for p in all_pdfs],
                                api_key=api_key,
                            )
                            st.session_state.vectorstore = vectorstore
                            st.session_state.rag_engine = RAGEngine(vectorstore, api_key)
                            st.session_state.indexed_files = [p.name for p in all_pdfs]
                            st.session_state.indexed_chunks = vectorstore.index.ntotal
                            st.rerun()
                        except Exception as e:
                            st.error(f"ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
            else:
                st.success(
                    f"âœ… ì¸ë±ì‹± ì™„ë£Œ â€” {len(st.session_state.indexed_files)}ê°œ ë¬¸ì„œ / "
                    f"{st.session_state.indexed_chunks}ê°œ ì²­í¬"
                )

    st.divider()

    # â”€â”€ Step 2: ë¬¸ì„œ ìƒì„± â”€â”€
    st.header("Step 2: ë¬¸ì„œ ìƒì„±")

    rag_engine: RAGEngine | None = st.session_state.rag_engine

    if not rag_engine:
        st.info("Step 1ì—ì„œ Master Dataë¥¼ ì¸ë±ì‹±í•˜ì„¸ìš”.")
    elif not hospital:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ë³‘ì›ì„ ì„ íƒí•˜ì„¸ìš”. ë³‘ì›ì´ ì—†ìœ¼ë©´ **ë³‘ì› ì–‘ì‹ ê´€ë¦¬** íƒ­ì—ì„œ ë¨¼ì € ë“±ë¡í•˜ì„¸ìš”.")
    else:
        template_path = TEMPLATES_DIR / hospital["template_file"]

        if not template_path.exists():
            st.error(f"í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{template_path}`")
            st.stop()

        # ì–‘ì‹ ë¶„ì„ â€” {{placeholder}} íƒœê·¸ íƒì§€
        placeholders = find_placeholders_in_doc(template_path)

        if not placeholders:
            st.warning(
                "ì–‘ì‹ì—ì„œ `{{íƒœê·¸}}` í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. "
                "í…œí”Œë¦¿ì— `{{placeholder}}` íƒœê·¸ê°€ ì‚½ì…ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            )
        else:
            st.info(f"ì–‘ì‹ì—ì„œ **{len(placeholders)}ê°œ í•­ëª©** íƒì§€ ì™„ë£Œ")

            with st.expander("íƒì§€ëœ í•­ëª© ëª©ë¡", expanded=False):
                for i, key in enumerate(placeholders, 1):
                    query = PLACEHOLDER_QUERIES.get(key, key)
                    st.write(f"{i}. `{{{{{key}}}}}` â€” {query[:60]}")

            if st.button("ğŸ¤– ë¬¸ì„œ ìƒì„±", type="primary", key="gen_auto"):
                progress = st.progress(0)
                status = st.empty()
                replacements: dict[str, str] = {}
                sources_info: dict[str, list[str]] = {}

                for i, key in enumerate(placeholders):
                    query_text = PLACEHOLDER_QUERIES.get(key, key)
                    status.write(f"ì²˜ë¦¬ ì¤‘: **{key}** ({i+1}/{len(placeholders)})")
                    try:
                        result = rag_engine.query(
                            field_id=key,
                            custom_query=query_text,
                        )
                        replacements[key] = result.answer
                        sources_info[key] = result.sources
                    except Exception as e:
                        replacements[key] = f"[ìƒì„± ì‹¤íŒ¨: {e}]"
                        sources_info[key] = []
                        logger.error("ì§ˆì˜ ì‹¤íŒ¨: %s â€” %s", key, e)
                    progress.progress((i + 1) / len(placeholders))

                st.session_state.generated_results = replacements
                st.session_state.generated_sources = sources_info

                status.empty()
                progress.empty()

                # ìƒì„± ê²°ê³¼ ìš”ì•½
                success_count = sum(1 for v in replacements.values() if not v.startswith("[ìƒì„± ì‹¤íŒ¨"))
                empty_count = sum(1 for v in replacements.values() if v.strip() in ("", "í•´ë‹¹ ì •ë³´ ì—†ìŒ"))
                fail_count = sum(1 for v in replacements.values() if v.startswith("[ìƒì„± ì‹¤íŒ¨"))

                if fail_count == 0 and empty_count == 0:
                    st.success(f"âœ… ë¬¸ì„œ ìƒì„± ì™„ë£Œ! ({success_count}ê°œ í•­ëª© ëª¨ë‘ ì„±ê³µ)")
                elif fail_count > 0:
                    st.warning(f"âš ï¸ ë¬¸ì„œ ìƒì„± ì™„ë£Œ â€” ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {fail_count}ê°œ, ì •ë³´ ì—†ìŒ: {empty_count}ê°œ")
                else:
                    st.info(f"ğŸ“„ ë¬¸ì„œ ìƒì„± ì™„ë£Œ â€” ì„±ê³µ: {success_count}ê°œ, ì •ë³´ ì—†ìŒ: {empty_count}ê°œ")

    st.divider()

    # â”€â”€ Step 3: ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ â”€â”€
    st.header("Step 3: ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ")

    generated: dict[str, str] = st.session_state.generated_results

    if not generated:
        st.info("Step 2ì—ì„œ ë¬¸ì„œë¥¼ ìƒì„±í•˜ì„¸ìš”.")
    else:
        sources_data: dict = st.session_state.get("generated_sources", {})
        st.write(f"**{len(generated)}ê°œ í•­ëª©** ìƒì„± ì™„ë£Œ. ë‚´ìš©ì„ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•˜ì„¸ìš”.")

        edited_results: dict[str, str] = {}
        for i, (key, answer) in enumerate(generated.items()):
            query_desc = PLACEHOLDER_QUERIES.get(key, key)[:40]

            # í’ˆì§ˆ ì§€í‘œ
            if answer.startswith("[ìƒì„± ì‹¤íŒ¨"):
                quality = "âŒ ì‹¤íŒ¨"
            elif answer.strip() in ("", "í•´ë‹¹ ì •ë³´ ì—†ìŒ"):
                quality = "âš ï¸ ì •ë³´ ì—†ìŒ"
            elif len(answer.strip()) < 10:
                quality = "âš ï¸ ì§§ìŒ"
            else:
                quality = "âœ…"

            with st.expander(f"{quality} {key} â€” {query_desc}", expanded=(quality != "âœ…")):
                edited = st.text_area(
                    "ë‚´ìš©",
                    value=answer,
                    height=200,
                    key=f"edit_{i}",
                    label_visibility="collapsed",
                )
                edited_results[key] = edited

                # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
                key_sources = sources_data.get(key, [])
                if key_sources:
                    st.caption(f"ğŸ“š ì°¸ì¡° ì†ŒìŠ¤: {', '.join(key_sources)}")
                elif quality == "âœ…":
                    st.caption("ğŸ“š ì°¸ì¡° ì†ŒìŠ¤: (ì •ë³´ ì—†ìŒ)")

        st.session_state.generated_results = edited_results

        st.divider()

        if hospital:
            template_path = TEMPLATES_DIR / hospital["template_file"]
            if template_path.exists() and edited_results:
                try:
                    doc_bytes = replace_placeholders_to_bytes(
                        doc_path=template_path,
                        replacements=edited_results,
                    )
                    product_name = product["id"] if product else "unknown"
                    hospital_name = hospital["id"] if hospital else "unknown"
                    download_name = f"DC_{product_name}_{hospital_name}.docx"

                    st.download_button(
                        label="â¬‡ï¸ ì™„ì„±ëœ .docx ë‹¤ìš´ë¡œë“œ",
                        data=doc_bytes,
                        file_name=download_name,
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        type="primary",
                    )
                except Exception as e:
                    st.error(f"íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# íƒ­ 2: ë³‘ì› ì–‘ì‹ ê´€ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab_hospitals:
    st.header("ğŸ¥ ë³‘ì› ì–‘ì‹ ê´€ë¦¬")
    st.caption("ë³‘ì›ë³„ DC ì‹ ì²­ ì–‘ì‹(.docx)ì„ ë“±ë¡í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.")

    # â”€â”€ ë“±ë¡ëœ ë³‘ì› ëª©ë¡ â”€â”€
    try:
        h_data = _load_json(HOSPITAL_META_PATH)
        h_list = h_data.get("hospitals", [])
    except FileNotFoundError:
        h_data = {"hospitals": []}
        h_list = []

    display_list = [h for h in h_list if h.get("id") != "sample_hospital"]

    st.subheader(f"ë“±ë¡ëœ ë³‘ì› ({len(display_list)}ê°œ)")

    if display_list:
        for h in display_list:
            col_name, col_status, col_file, col_dl, col_del = st.columns([3, 1.5, 3, 1, 1])

            col_name.write(f"**{h['name']}**")

            # ìƒíƒœ ë°°ì§€ + íƒœê·¸ ìˆ˜ í‘œì‹œ
            is_ready = h.get("mode") == "manual"
            tmpl_path = TEMPLATES_DIR / h["template_file"]
            if is_ready and tmpl_path.exists():
                tag_count = len(find_placeholders_in_doc(tmpl_path))
                col_status.success(f"âœ… íƒœê·¸ {tag_count}ê°œ")
            elif is_ready:
                col_status.success("âœ… ì¤€ë¹„ë¨")
            else:
                col_status.warning("âš ï¸ íƒœê·¸ í•„ìš”")

            col_file.write(f"`{h['template_file']}`")

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (íƒœê·¸ëœ íŒŒì¼)
            if tmpl_path.exists():
                with open(tmpl_path, "rb") as dl_f:
                    col_dl.download_button(
                        label="â¬‡ï¸",
                        data=dl_f.read(),
                        file_name=h["template_file"],
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key=f"dl_{h['id']}",
                    )

            # ì‚­ì œ ë²„íŠ¼
            if col_del.button("ì‚­ì œ", key=f"del_{h['id']}"):
                # ë³‘ì› ëª©ë¡ì—ì„œ ì œê±°
                h_data["hospitals"] = [x for x in h_data["hospitals"] if x["id"] != h["id"]]
                _save_json(HOSPITAL_META_PATH, h_data)
                # í…œí”Œë¦¿ íŒŒì¼ë„ ì‚­ì œ
                tmpl = TEMPLATES_DIR / h["template_file"]
                if tmpl.exists():
                    tmpl.unlink()
                if st.session_state.selected_hospital and st.session_state.selected_hospital.get("id") == h["id"]:
                    st.session_state.selected_hospital = None
                st.rerun()

            # íƒœê·¸ ì§„ë‹¨ expander (ì¤€ë¹„ë¨ ìƒíƒœì¼ ë•Œ)
            if is_ready and tmpl_path.exists():
                with st.expander(f"ğŸ” {h['name']} â€” ì‚½ì…ëœ íƒœê·¸ ëª©ë¡", expanded=False):
                    tags = find_placeholders_in_doc(tmpl_path)
                    if tags:
                        for idx, tag_key in enumerate(tags, 1):
                            query_desc = PLACEHOLDER_QUERIES.get(tag_key, "ì•Œ ìˆ˜ ì—†ëŠ” í‚¤")
                            st.write(f"{idx}. `{{{{{tag_key}}}}}` â†’ {query_desc[:60]}")
                    else:
                        st.warning("íƒœê·¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íƒœê·¸ê°€ ì˜¬ë°”ë¥´ê²Œ ì‚½ì…ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    else:
        st.info("ë“±ë¡ëœ ë³‘ì›ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ìƒˆ ë³‘ì›ì„ ì¶”ê°€í•˜ì„¸ìš”.")

    st.divider()

    # â”€â”€ ìƒˆ ë³‘ì› ì¶”ê°€ â”€â”€
    st.subheader("â• ìƒˆ ë³‘ì› ì¶”ê°€")

    hospital_name_input = st.text_input(
        "ë³‘ì› ì´ë¦„ *",
        placeholder="ì˜ˆ: ì„œìš¸ëŒ€í•™êµë³‘ì›",
        key="new_hospital_name",
    )

    template_file_input = st.file_uploader(
        "ë³‘ì› ì–‘ì‹ íŒŒì¼ ì—…ë¡œë“œ * (.docx)",
        type=["docx"],
        key="new_hospital_file",
        help="ë³‘ì›ì—ì„œ ìš”êµ¬í•˜ëŠ” DC ì‹ ì²­ ì–‘ì‹ Word íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
    )

    if st.button("ë³‘ì› ë“±ë¡", type="primary", key="register_hospital_btn"):
        if not hospital_name_input:
            st.error("ë³‘ì› ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.")
        elif not template_file_input:
            st.error("ì–‘ì‹ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            # ë³‘ì› ID ìƒì„± (ì´ë¦„ â†’ ì˜ë¬¸ ì†Œë¬¸ì + íƒ€ì„ìŠ¤íƒ¬í”„)
            hospital_id = re.sub(r"[^a-zA-Z0-9ê°€-í£]", "_", hospital_name_input).lower()
            hospital_id = f"{hospital_id}_{int(time.time())}"

            # íŒŒì¼ëª…: ë³‘ì›ID.docx
            template_filename = f"{hospital_id}.docx"
            save_path = TEMPLATES_DIR / template_filename

            # íŒŒì¼ ì €ì¥
            with open(save_path, "wb") as f:
                f.write(template_file_input.getbuffer())

            # ìë™ ê°ì§€: ê¸°ì¡´ {{placeholder}} íƒœê·¸ í™•ì¸
            detected_placeholders = find_placeholders_in_doc(save_path)
            detected_mode = "manual" if detected_placeholders else "needs_tagging"

            # hospital_meta.json ì—…ë°ì´íŠ¸
            new_entry = {
                "id": hospital_id,
                "name": hospital_name_input,
                "template_file": template_filename,
                "format": "docx",
                "mode": detected_mode,
                "field_mapping": None,
            }
            h_data["hospitals"].append(new_entry)
            _save_json(HOSPITAL_META_PATH, h_data)

            if detected_mode == "manual":
                # íƒœê·¸ê°€ ì´ë¯¸ ìˆìŒ â€” ì™„ë£Œ
                st.success(
                    f"âœ… **{hospital_name_input}** ë“±ë¡ ì™„ë£Œ! "
                    f"{{{{placeholder}}}} íƒœê·¸ {len(detected_placeholders)}ê°œ ë°œê²¬. "
                    f"ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”."
                )
                st.rerun()
            else:
                # íƒœê·¸ ì—†ìŒ â€” AI ìë™ ë¶„ì„ í›„ ì €ì¥
                tag_api_key = st.session_state.google_api_key
                if not tag_api_key:
                    st.warning(
                        f"âš ï¸ **{hospital_name_input}** ë“±ë¡ ì™„ë£Œ (íƒœê·¸ ë¯¸ì„¤ì •). "
                        f"Google API í‚¤ë¥¼ ì…ë ¥í•œ í›„ ë‹¤ì‹œ ë“±ë¡í•˜ê±°ë‚˜, ì§ì ‘ {{{{íƒœê·¸}}}}ë¥¼ íŒŒì¼ì— ì¶”ê°€í•´ì£¼ì„¸ìš”."
                    )
                    st.rerun()
                else:
                    with st.spinner("ğŸ¤– AIê°€ ì–‘ì‹ì„ ë¶„ì„í•˜ê³  íƒœê·¸ë¥¼ ìë™ ì‚½ì… ì¤‘..."):
                        cells = detect_taggable_cells(save_path)
                        # LABEL_ONLY ì…€ë§Œ AI íƒœê·¸ ëŒ€ìƒ
                        label_cells = [c for c in cells if c.cell_type == CellType.LABEL_ONLY]
                        if label_cells:
                            tag_engine = RAGEngine(vectorstore=None, api_key=tag_api_key)
                            auto_mappings = tag_engine.generate_cell_tags(
                                cells=label_cells,
                                placeholder_queries=PLACEHOLDER_QUERIES,
                            )
                            # ì¢Œí‘œ ê¸°ë°˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë§¤í•‘ (ìˆœì„œ ë¶ˆì¼ì¹˜ ë²„ê·¸ í•´ê²°)
                            mapping_lookup = {
                                (m.table_index, m.row_index, m.cell_index): m.placeholder_key
                                for m in auto_mappings
                                if m.placeholder_key not in ("unknown", "")
                            }
                            auto_assignments = [
                                (c, mapping_lookup[(c.table_index, c.row_index, c.cell_index)])
                                for c in label_cells
                                if (c.table_index, c.row_index, c.cell_index) in mapping_lookup
                            ]
                            if auto_assignments:
                                tagged_bytes = insert_placeholder_tags(str(save_path), auto_assignments)
                                with open(save_path, "wb") as f:
                                    f.write(tagged_bytes)
                                # mode ì—…ë°ì´íŠ¸
                                for h_entry in h_data["hospitals"]:
                                    if h_entry["id"] == hospital_id:
                                        h_entry["mode"] = "manual"
                                        break
                                _save_json(HOSPITAL_META_PATH, h_data)
                                st.success(
                                    f"âœ… **{hospital_name_input}** ë“±ë¡ ì™„ë£Œ! "
                                    f"AIê°€ {len(auto_assignments)}ê°œ íƒœê·¸ë¥¼ ìë™ ì‚½ì…í–ˆìŠµë‹ˆë‹¤."
                                )
                            else:
                                st.warning(
                                    f"âš ï¸ **{hospital_name_input}** ë“±ë¡ ì™„ë£Œ. "
                                    f"AIê°€ ìœ íš¨í•œ íƒœê·¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ì ‘ {{{{íƒœê·¸}}}}ë¥¼ íŒŒì¼ì— ì¶”ê°€í•˜ê±°ë‚˜, ë‹¤ì‹œ ë“±ë¡í•´ì£¼ì„¸ìš”."
                                )
                        else:
                            st.warning(
                                f"âš ï¸ **{hospital_name_input}** ë“±ë¡ ì™„ë£Œ. "
                                f"ì–‘ì‹ì—ì„œ íƒœê·¸ ê°€ëŠ¥í•œ ì…€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                            )
                    st.rerun()

    st.divider()
